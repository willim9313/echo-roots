#!/usr/bin/env python3
"""
ç°¡åŒ–ç‰ˆ LLM API æ¸¬è©¦è…³æœ¬
ç”¨æ–¼å¿«é€Ÿé©—è­‰æ‚¨çš„ LLM API æ•´åˆ
"""

import asyncio
import json
import os
import sys
import time
from datetime import datetime
from pathlib import Path
import aiohttp

# è¨­å®š API é‡‘é‘° (è«‹æ›¿æ›ç‚ºæ‚¨çš„å¯¦éš›é‡‘é‘°)
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY', 'your-api-key-here')
MODEL_NAME = os.getenv('OPENAI_MODEL', 'gpt-4')


class SimpleLLMClient:
    """ç°¡åŒ–çš„ LLM å®¢æˆ¶ç«¯ï¼Œç”¨æ–¼å¿«é€Ÿæ¸¬è©¦"""
    
    def __init__(self, api_key: str, model_name: str = "gpt-4"):
        self.api_key = api_key
        self.model_name = model_name
        self.base_url = 'https://api.openai.com/v1'
        self.session = None
    
    async def complete(self, prompt: str) -> str:
        """ç™¼é€è«‹æ±‚åˆ° LLM API"""
        if not self.session:
            self.session = aiohttp.ClientSession()
        
        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }
        
        payload = {
            'model': self.model_name,
            'messages': [
                {'role': 'system', 'content': 'You are a helpful assistant. Return valid JSON only.'},
                {'role': 'user', 'content': prompt}
            ],
            'temperature': 0.3,
            'max_tokens': 1000
        }
        
        try:
            async with self.session.post(
                f'{self.base_url}/chat/completions',
                headers=headers,
                json=payload,
                timeout=30
            ) as response:
                if response.status == 200:
                    data = await response.json()
                    return data['choices'][0]['message']['content'].strip()
                else:
                    error_text = await response.text()
                    raise Exception(f"API Error {response.status}: {error_text}")
                    
        except Exception as e:
            raise Exception(f"LLM API call failed: {str(e)}")
    
    async def close(self):
        if self.session:
            await self.session.close()


async def test_product_extraction():
    """æ¸¬è©¦ç”¢å“å±¬æ€§æå–"""
    
    print("ğŸ¤– æ¸¬è©¦ LLM API ç”¢å“å±¬æ€§æå–")
    print("=" * 50)
    
    # æª¢æŸ¥ API é‡‘é‘°
    if OPENAI_API_KEY == 'your-api-key-here':
        print("âŒ è«‹è¨­å®šæ‚¨çš„ OPENAI_API_KEY ç’°å¢ƒè®Šæ•¸")
        print("åŸ·è¡Œ: export OPENAI_API_KEY='your-actual-api-key'")
        return
    
    # å‰µå»º LLM å®¢æˆ¶ç«¯
    llm_client = SimpleLLMClient(OPENAI_API_KEY, MODEL_NAME)
    
    # æ¸¬è©¦ç”¢å“è³‡æ–™
    test_products = [
        {
            "title": "iPhone 15 Pro 256GB é»‘è‰²",
            "description": "è˜‹æœæœ€æ–°æ——è‰¦æ‰‹æ©Ÿï¼Œ6.1å‹è¶…ç´šè¦–ç¶²è†œXDRé¡¯ç¤ºå™¨ï¼ŒA17 Proæ™¶ç‰‡ï¼Œä¸‰é¡é ­ç›¸æ©Ÿç³»çµ±ï¼Œæ”¯æ´5G"
        },
        {
            "title": "Samsung Galaxy S24 Ultra",
            "description": "ä¸‰æ˜Ÿé ‚ç´šæ™ºæ…§å‹æ‰‹æ©Ÿï¼Œ6.8å‹AMOLEDè¢å¹•ï¼ŒSnapdragon 8 Gen 3è™•ç†å™¨ï¼ŒS Penæ‰‹å¯«ç­†"
        },
        {
            "title": "MacBook Air M2 13å‹ 8GB/256GB å¤ªç©ºç°",
            "description": "è˜‹æœç­†è¨˜å‹é›»è…¦ï¼ŒM2æ™¶ç‰‡ï¼Œ13.6å‹Liquid Retinaé¡¯ç¤ºå™¨ï¼Œå…¨å¤©å€™é›»æ± çºŒèˆªåŠ›"
        }
    ]
    
    try:
        for i, product in enumerate(test_products, 1):
            print(f"\nğŸ“± æ¸¬è©¦ç”¢å“ {i}: {product['title']}")
            
            # æ§‹å»ºæå–æç¤º
            prompt = f"""
è«‹å¾ä»¥ä¸‹ç”¢å“è³‡è¨Šä¸­æå–çµæ§‹åŒ–å±¬æ€§ï¼š

ç”¢å“æ¨™é¡Œ: {product['title']}
ç”¢å“æè¿°: {product['description']}

è«‹ä»¥ JSON æ ¼å¼å›æ‡‰ï¼ŒåŒ…å«ä»¥ä¸‹æ¬„ä½ï¼š
{{
    "brand": "å“ç‰Œåç¨±",
    "model": "å‹è™Ÿ",
    "color": "é¡è‰²",
    "storage": "å„²å­˜å®¹é‡",
    "screen_size": "è¢å¹•å°ºå¯¸",
    "price_tier": "åƒ¹æ ¼ç­‰ç´š (budget/mid-range/premium)",
    "category": "ç”¢å“é¡åˆ¥",
    "key_features": ["ä¸»è¦ç‰¹è‰²1", "ä¸»è¦ç‰¹è‰²2", "ä¸»è¦ç‰¹è‰²3"]
}}

åªå›å‚³æœ‰æ•ˆçš„ JSONï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—ã€‚
"""
            
            start_time = time.time()
            
            # èª¿ç”¨ LLM
            response = await llm_client.complete(prompt)
            
            processing_time = int((time.time() - start_time) * 1000)
            
            # è§£æå›æ‡‰
            try:
                result = json.loads(response)
                
                print(f"âœ… æå–æˆåŠŸ (è€—æ™‚: {processing_time}ms)")
                print(f"   å“ç‰Œ: {result.get('brand', 'N/A')}")
                print(f"   å‹è™Ÿ: {result.get('model', 'N/A')}")
                print(f"   é¡è‰²: {result.get('color', 'N/A')}")
                print(f"   å®¹é‡: {result.get('storage', 'N/A')}")
                print(f"   è¢å¹•: {result.get('screen_size', 'N/A')}")
                print(f"   ç­‰ç´š: {result.get('price_tier', 'N/A')}")
                print(f"   é¡åˆ¥: {result.get('category', 'N/A')}")
                
                features = result.get('key_features', [])
                if features:
                    print(f"   ç‰¹è‰²: {', '.join(features[:3])}")
                
            except json.JSONDecodeError:
                print(f"âŒ JSON è§£æå¤±æ•—")
                print(f"åŸå§‹å›æ‡‰: {response[:200]}...")
    
        print(f"\nğŸ¯ ä½¿ç”¨æ¨¡å‹: {MODEL_NAME}")
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {str(e)}")
        
    finally:
        await llm_client.close()


async def test_category_classification():
    """æ¸¬è©¦ç”¢å“åˆ†é¡"""
    
    print("\nğŸ·ï¸ æ¸¬è©¦ç”¢å“åˆ†é¡")
    print("-" * 30)
    
    if OPENAI_API_KEY == 'your-api-key-here':
        return
    
    llm_client = SimpleLLMClient(OPENAI_API_KEY, MODEL_NAME)
    
    test_items = [
        "Nike Air Max 270 ç”·æ¬¾é‹å‹•é‹",
        "Sony WH-1000XM5 ç„¡ç·šé™å™ªè€³æ©Ÿ",
        "Dyson V15 Detect ç„¡ç·šå¸å¡µå™¨",
        "ç¾çš„é›»ç£çˆIHæ™ºèƒ½è§¸æ§é¢æ¿"
    ]
    
    # å¯ç”¨é¡åˆ¥ (ç°¡åŒ–ç‰ˆ)
    categories = [
        "æœè£é…ä»¶", "é‹é¡", "é›»å­ç”¢å“", "å®¶é›»ç”¨å“", 
        "é‹å‹•ç”¨å“", "ç¾å®¹ä¿é¤Š", "å®¶å±…ç”¨å“", "æ±½è»Šç”¨å“"
    ]
    
    try:
        for item in test_items:
            prompt = f"""
è«‹å°‡ä»¥ä¸‹ç”¢å“åˆ†é¡åˆ°æœ€åˆé©çš„é¡åˆ¥ä¸­ï¼š

ç”¢å“: {item}

å¯ç”¨é¡åˆ¥: {', '.join(categories)}

è«‹å›å‚³ JSON æ ¼å¼:
{{
    "predicted_category": "æœ€åˆé©çš„é¡åˆ¥",
    "confidence": 0.95
}}
"""
            
            response = await llm_client.complete(prompt)
            
            try:
                result = json.loads(response)
                category = result.get('predicted_category', 'N/A')
                confidence = result.get('confidence', 0.0)
                
                print(f"ğŸ“¦ {item}")
                print(f"   â†’ {category} (ä¿¡å¿ƒåº¦: {confidence:.2f})")
                
            except json.JSONDecodeError:
                print(f"âŒ åˆ†é¡å¤±æ•—: {item}")
    
    except Exception as e:
        print(f"âŒ åˆ†é¡æ¸¬è©¦å¤±æ•—: {str(e)}")
        
    finally:
        await llm_client.close()


async def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    
    print("ğŸš€ Echo-Roots LLM API æ•´åˆæ¸¬è©¦")
    print("=" * 50)
    
    # æª¢æŸ¥ä¾è³´
    try:
        import aiohttp
    except ImportError:
        print("âŒ éœ€è¦å®‰è£ aiohttp: pip install aiohttp")
        return
    
    # åŸ·è¡Œæ¸¬è©¦
    await test_product_extraction()
    await test_category_classification()
    
    print("\nâœ… æ¸¬è©¦å®Œæˆï¼")
    print("\nä¸‹ä¸€æ­¥ï¼š")
    print("1. å¦‚æœæ¸¬è©¦æˆåŠŸï¼Œæ‚¨å¯ä»¥å°‡é€™å€‹ LLM å®¢æˆ¶ç«¯æ•´åˆåˆ° Echo-Roots ä¸­")
    print("2. ä½¿ç”¨ run_real_llm.py é€²è¡Œå®Œæ•´çš„ Echo-Roots æ•´åˆæ¸¬è©¦")
    print("3. æ ¹æ“šéœ€è¦èª¿æ•´æç¤ºæ¨¡æ¿å’Œåƒæ•¸")


if __name__ == "__main__":
    asyncio.run(main())
